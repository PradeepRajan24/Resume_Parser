{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PradeepRajan24/Resume_Parser/blob/main/ResumeParser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install the needed Libraries"
      ],
      "metadata": {
        "id": "itKeWJLAIZhJ"
      },
      "id": "itKeWJLAIZhJ"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3c9a2013",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c9a2013",
        "outputId": "de3b2d62-12e2-40af-887c-f319c308cc35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.2/440.2 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m100.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.7/367.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.2/211.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.5/585.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.5/305.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-core langchain_huggingface transformers pdfplumber python-docx pypandoc unstructured accelerate --upgrade --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Import the necesary libraries"
      ],
      "metadata": {
        "id": "VGRVK4ajIhTh"
      },
      "id": "VGRVK4ajIhTh"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d067cdef",
      "metadata": {
        "id": "d067cdef"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "from langchain_community.document_loaders import PDFPlumberLoader, UnstructuredWordDocumentLoader\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "from langchain_huggingface.llms import HuggingFacePipeline\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "import torch\n",
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Reading the text from PDF or Word files by detecting the file type and using the appropriate document loader to extract the text"
      ],
      "metadata": {
        "id": "CY6dWoXNIn3a"
      },
      "id": "CY6dWoXNIn3a"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "93d53725",
      "metadata": {
        "id": "93d53725"
      },
      "outputs": [],
      "source": [
        "def extract_text_from_document(file_path):\n",
        "    file_extension = os.path.splitext(file_path)[1].lower()\n",
        "\n",
        "    if file_extension == '.pdf':\n",
        "        loader = PDFPlumberLoader(file_path)\n",
        "    elif file_extension in ['.docx', '.doc']:\n",
        "        loader = UnstructuredWordDocumentLoader(file_path)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {file_extension}. Only .pdf, .docx, .doc are accepted.\")\n",
        "\n",
        "    docs = loader.load()\n",
        "    text = \"\\n\".join(doc.page_content for doc in docs)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Defining the role or behaviour for the LLM"
      ],
      "metadata": {
        "id": "ujVOiXzjIwV3"
      },
      "id": "ujVOiXzjIwV3"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "66fe460d",
      "metadata": {
        "id": "66fe460d"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"\"\"You are a highly skilled AI resume parser. Your task is to extract all relevant information from the provided resume text and format it into a structured JSON object.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "28c0bfd5",
      "metadata": {
        "id": "28c0bfd5"
      },
      "outputs": [],
      "source": [
        "human_prompt = \"\"\"\n",
        "             **Task:** Extract key information from the following resume text.\n",
        "\n",
        "            **Resume Text:**\n",
        "            {context}\n",
        "\n",
        "\n",
        "**Instructions:**\n",
        "Please extract the following information from the resume and structure it into a single JSON object. Ensure the JSON adheres strictly to the specified schema below. Use `null` for any missing or unavailable values.\n",
        "\n",
        "**JSON Schema Requirements:**\n",
        "\n",
        "* **Top-level fields:**\n",
        "    * `first_name` (string): The candidate's first name.\n",
        "    * `last_name` (string): The candidate's last name.\n",
        "    * `email` (string): The candidate's email address.\n",
        "    * `phone` (string): The candidate's phone number.\n",
        "    * `summary` (string): A concise summary or objective or personnel statement from the resume.\n",
        "    * `address` (object):\n",
        "        * `city` (string): The city from the address.\n",
        "        * `state` (string): The state from the address.\n",
        "        * `country` (string): The country from the address.\n",
        "    * `education_history` (array of objects):\n",
        "        * Each object represents an educational entry and must contain:\n",
        "            * `name` (string): Name of the institution.\n",
        "            * `degree` (string): Degree obtained.\n",
        "            * `from_date` (string): Start date of education (e.g., \"MM-DD-YYYY\" or \"YYYY\" or null).\n",
        "            * `to_date` (string): End date of education (e.g., \"MM-DD-YYYY\" or \"YYYY\" or present or null).\n",
        "    * `work_history` (array of objects):\n",
        "        * Each object represents a work experience entry and must contain:\n",
        "            * `company` (string): Name of the company.\n",
        "            * `title` (string): Job title.\n",
        "            * `from_date` (string): Start date of employment (e.g., \"MM-DD-YYYY\" or \"YYYY\" or null).\n",
        "            * `to_date` (string): End date of employment (e.g., \"MM-DD-YYYY\" or \"YYYY\" or present or null).\n",
        "            * `description` (string): A detailed description of responsibilities and achievements in that role.\n",
        "    * `skills` (array of objects):\n",
        "        * Each object represents a single skill and must contain:\n",
        "            * `skill` (string): The name of the skill.\n",
        "\n",
        "**Question:**\n",
        "Provide the extracted information as a single, valid JSON object following the exact schema described above.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Specifying the paths to read the contents from the file and then extracting text to analyse it"
      ],
      "metadata": {
        "id": "0HD146ZBLJ8G"
      },
      "id": "0HD146ZBLJ8G"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "66b04cce",
      "metadata": {
        "id": "66b04cce"
      },
      "outputs": [],
      "source": [
        "pdf_path = \"/content/Pradeep_Rajan_2405_CV.pdf\"\n",
        "#docx_path=\"\"\n",
        "#doc_path=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4b3995d",
      "metadata": {
        "id": "d4b3995d"
      },
      "outputs": [],
      "source": [
        "context = extract_text_from_document(pdf_path)\n",
        "print(context)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Using a prompt template to combine the systems role with the human input for the LLM."
      ],
      "metadata": {
        "id": "EgClF-D0S9rV"
      },
      "id": "EgClF-D0S9rV"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c1950894",
      "metadata": {
        "id": "c1950894"
      },
      "outputs": [],
      "source": [
        "template = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", human_prompt),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "86796103",
      "metadata": {
        "id": "86796103"
      },
      "outputs": [],
      "source": [
        "complete_prompt = template.format_messages(context=context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2e41b2a9",
      "metadata": {
        "id": "2e41b2a9"
      },
      "outputs": [],
      "source": [
        "complete_prompt = [text.content.replace(\"•\", \" \") for text in complete_prompt]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Using Meta LLaMA 3 70B Instruct model and its tokenizer from Hugging Face to perform text generation tasks"
      ],
      "metadata": {
        "id": "4bCYAjHeTikz"
      },
      "id": "4bCYAjHeTikz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7da105",
      "metadata": {
        "collapsed": true,
        "id": "1f7da105"
      },
      "outputs": [],
      "source": [
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88432e1c",
      "metadata": {
        "id": "88432e1c"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "# task = \"text-generation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "232e029e",
      "metadata": {
        "id": "232e029e"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3-70B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3-70B-Instruct\", device_map=\"auto\")\n",
        "task = \"text-generation\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d4469e",
      "metadata": {
        "collapsed": true,
        "id": "52d4469e"
      },
      "outputs": [],
      "source": [
        "#pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "929f44e8",
      "metadata": {
        "id": "929f44e8"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    task,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=2048,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Invoking the LLM to generate a JSON-formatted output based on the full prompt, and then parsing that string into a Python dictionary using json.loads()"
      ],
      "metadata": {
        "id": "AHuTC7F-T7ph"
      },
      "id": "AHuTC7F-T7ph"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e38d6cc",
      "metadata": {
        "id": "6e38d6cc"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac7d4598",
      "metadata": {
        "id": "ac7d4598"
      },
      "outputs": [],
      "source": [
        "json_output = llm.invoke(complete_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed02c8a",
      "metadata": {
        "id": "0ed02c8a"
      },
      "outputs": [],
      "source": [
        "print(json_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fc0345b",
      "metadata": {
        "id": "8fc0345b"
      },
      "outputs": [],
      "source": [
        "output_filename = \"output.json\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_json = json.loads(json_output)"
      ],
      "metadata": {
        "id": "uawPmFjcGihg"
      },
      "id": "uawPmFjcGihg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. The desired JSON output file can be downloaded using this"
      ],
      "metadata": {
        "id": "ZUPz8vTCUAMe"
      },
      "id": "ZUPz8vTCUAMe"
    },
    {
      "cell_type": "code",
      "source": [
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "        json.dump(parsed_json, f, indent=2, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "mfpxeenpGk1e"
      },
      "id": "mfpxeenpGk1e",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}